{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 7\n",
    "DATA_DIR = \"../../../data/\"\n",
    "INTERM_DIR = '../compiled_data'\n",
    "\n",
    "twitter_data_path = os.path.join(DATA_DIR, 'tweets/tweets_data_final.csv')\n",
    "bitcoin_data_path = os.path.join(DATA_DIR, 'bitcoin_price/archive/BTC-USD.csv')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(twitter_data_path)\n",
    "#pd.read_csv(bitcoin_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_twitter_data(data_path, nrows=None, cols=['text', 'conversation_id','created_at', 'retweet_count', 'reply_count', 'like_count','quote_count', 'is_reply_to_user', 'related_user_id',]):\n",
    "    \"Load twitter data, nrows None indicates all rows, otherwise specified integer of rows\"\n",
    "    data = pd.read_csv(data_path, nrows = nrows, delimiter=',', usecols=cols)\n",
    "    data = data[data['text'] != '']\n",
    "    data['created_at'] = pd.to_datetime(data['created_at']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bitcoin(data_path):\n",
    "    asset = pd.read_csv(data_path)\n",
    "    asset = asset.dropna()\n",
    "    asset[\"log_ret\"] = np.log(asset.prc).diff(1)\n",
    "    return asset[\"log_ret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = load_twitter_data(twitter_data_path, None)\n",
    "#bitcoin_df = load_bitcoin(bitcoin_data_path, None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Columns not found: 'is replies'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3bc2738274c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtwitter_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwitter_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"created_at\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromisoformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is replies'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1536\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m             )\n\u001b[0;32m-> 1538\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mbad_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Columns not found: {str(bad_keys)[1:-1]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Columns not found: 'is replies'\""
     ]
    }
   ],
   "source": [
    "twitter_df.groupby(twitter_df[\"created_at\"].apply(lambda x: datetime.datetime.fromisoformat(x)).dt.day)[['text', 'is replies']].count().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_url_at(df):\n",
    "    raw = []\n",
    "    for sentence in tqdm(df['text']):\n",
    "        sentence = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\n",
    "                          '(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', sentence)\n",
    "        sentence = re.sub(\"(@[A-Za-z0-9_]+)\", \"\", sentence)\n",
    "        raw.append(sentence)\n",
    "    df['text'] = raw\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagging(df):\n",
    "    pos,tag,dep,shape = [],[],[],[]\n",
    "    for sentence in tqdm(df['text']):\n",
    "        pos_tmp,tag_tmp,dep_tmp,shape_tmp = [],[],[],[]\n",
    "        for token in nlp(sentence):\n",
    "            pos_tmp.append(token.pos_)\n",
    "            tag_tmp.append(token.tag_)\n",
    "            dep_tmp.append(token.dep_)\n",
    "            shape_tmp.append(token.shape_)\n",
    "        pos.append(pos_tmp)\n",
    "        tag.append(tag_tmp)\n",
    "        dep.append(dep_tmp)\n",
    "        shape.append(shape_tmp)\n",
    "    df['Pos'] = pos\n",
    "    df['Tag'] = tag\n",
    "    df['Dep'] = dep\n",
    "    df['Shape'] = shape\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3678/3678 [00:00<00:00, 252490.26it/s]\n",
      "100%|██████████| 3678/3678 [00:45<00:00, 80.80it/s] \n"
     ]
    }
   ],
   "source": [
    "twitter_df = rem_url_at(twitter_df)\n",
    "twitter_df = tagging(twitter_df)\n",
    "twitter_df.replace('', np.nan, inplace=True)\n",
    "twitter_df = twitter_df.dropna(how='any', axis=0)\n",
    "twitter_df = twitter_df[twitter_df['text'].map(\n",
    "    lambda d: len(d)) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>is_reply_to_user</th>\n",
       "      <th>related_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If your long term conviction of bitcoin’s valu...</td>\n",
       "      <td>1525612785375264768</td>\n",
       "      <td>2022-05-14 23:03:27</td>\n",
       "      <td>378</td>\n",
       "      <td>196</td>\n",
       "      <td>2546</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>339061487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      conversation_id  \\\n",
       "0  If your long term conviction of bitcoin’s valu...  1525612785375264768   \n",
       "\n",
       "            created_at  retweet_count  reply_count  like_count  quote_count  \\\n",
       "0  2022-05-14 23:03:27            378          196        2546           42   \n",
       "\n",
       "   is_reply_to_user  related_user_id  \n",
       "0                 0        339061487  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analyser\n",
    "- Flair\n",
    "- Vader\n",
    "- Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 17:23:24,718 loading file /Users/ade/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "classifier = TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyser(df):\n",
    "    df_vader = []\n",
    "    for sentence in tqdm(df['text'], position=0):\n",
    "        df_vader.append(vader(sentence))\n",
    "    sa_df = pd.DataFrame(df_vader)\n",
    "    print(df.index, sa_df)\n",
    "    sa_df.index = df.index\n",
    "    df['neg_sa'] = sa_df['neg']\n",
    "    df['pos_sa'] = sa_df['pos']\n",
    "    df['neu_sa'] = sa_df['neu']\n",
    "    df['compound_sa'] = sa_df['compound']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader(sentence):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment = analyzer.polarity_scores(sentence)\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blob(sentence):\n",
    "    sentiment = TextBlob(sentence).sentiment.polarity\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fler(sentence):\n",
    "    s = Sentence(sentence)\n",
    "    classifier.predict(s)\n",
    "    sentiment = str(s.labels[0])\n",
    "    num = float(re.findall(r'\\d+\\.\\d+', sentiment)[0])\n",
    "    if sentiment.find('POSITIVE') == -1:\n",
    "        num = num * -1\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moved away from using multiple senttiment analysis models, too much computation time, Vader most adapted to social media\n",
    "# def sentiment_analyser(df, v=True, f=False, b=False, r_vader=0.8, r_fler=0.1, r_blob=0.1):\n",
    "#     df_fler, df_vader, df_blob = [], [], []\n",
    "#     for sentence in tqdm(df['body'], position=0):\n",
    "#         if v:\n",
    "#             df_vader.append(vader(sentence))\n",
    "#         if f:\n",
    "#             df_fler.append(fler(sentence))\n",
    "#         if b:\n",
    "#             df_blob.append(blob(sentence))\n",
    "#     if v: \n",
    "#         df['VADER'] = df_vader\n",
    "#     if f: \n",
    "#         df['FLAIR'] = df_fler\n",
    "#     if b:\n",
    "#         df['BLOB'] = df_blob\n",
    "#     if v and f and b:\n",
    "#         df['compound'] = df['VADER']*r_vader + \\\n",
    "#             df['FLAIR']*r_fler + df['BLOB']*r_blob\n",
    "#     elif v and f and not b:\n",
    "#         df['compound'] = df['VADER']*(r_vader+r_blob) + df['FLAIR']*r_fler\n",
    "#     elif v and b and not f:\n",
    "#         df['compound'] = df['VADER']*(r_vader+r_fler) + df['BLOB']*r_blob\n",
    "#     else:\n",
    "#         df['compound'] = df['VADER']\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We have helped nearly 1,000 people get a new job in the bitcoin and crypto industry over the last year. \\n\\nWe don't plan on stopping any time soon. \\n\\nThere are hundreds of open roles at the top companies in the industry. Come help build the future.\\n\\nAPPLY: https://t.co/EaWrk2lCb3\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = analyzer.polarity_scores(twitter_df['text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                We have helped nearly 1,000 people get a new j...\n",
       "conversation_id                                   1525490438093799424\n",
       "created_at                                        2022-05-14 14:57:17\n",
       "retweet_count                                                      50\n",
       "reply_count                                                        87\n",
       "like_count                                                        331\n",
       "quote_count                                                         4\n",
       "is_reply_to_user                                                    0\n",
       "related_user_id                                             339061487\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [00:02<00:00, 117.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text'], dtype='object')      neg  neu  pos  compound\n",
      "0    0.0  0.0  0.0       0.0\n",
      "1    0.0  0.0  0.0       0.0\n",
      "2    0.0  0.0  0.0       0.0\n",
      "3    0.0  0.0  0.0       0.0\n",
      "4    0.0  0.0  0.0       0.0\n",
      "..   ...  ...  ...       ...\n",
      "274  0.0  0.0  0.0       0.0\n",
      "275  0.0  0.0  0.0       0.0\n",
      "276  0.0  0.0  0.0       0.0\n",
      "277  0.0  0.0  0.0       0.0\n",
      "278  0.0  0.0  0.0       0.0\n",
      "\n",
      "[279 rows x 4 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 279 elements, new values have 1 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-474e830fa0c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtwitter_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment_analyser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwitter_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-4bab556838ea>\u001b[0m in \u001b[0;36msentiment_analyser\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msa_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_vader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msa_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neg_sa'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msa_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos_sa'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msa_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5498\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5499\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5501\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5502\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;34mf\"values have {new_len} elements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 279 elements, new values have 1 elements"
     ]
    }
   ],
   "source": [
    "twitter_df = sentiment_analyser(twitter_df[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text               We have helped nearly 1,000 people get a new j...\n",
       "conversation_id                                  1525490438093799424\n",
       "created_at                                       2022-05-14 14:57:17\n",
       "retweet_count                                                     50\n",
       "reply_count                                                       87\n",
       "neg_sa             0      0.0\n",
       "1      0.0\n",
       "2      0.0\n",
       "3      0.0\n",
       "4 ...\n",
       "pos_sa             0      0.0\n",
       "1      0.0\n",
       "2      0.0\n",
       "3      0.0\n",
       "4 ...\n",
       "neu_sa             0      0.0\n",
       "1      0.0\n",
       "2      0.0\n",
       "3      0.0\n",
       "4 ...\n",
       "compound_sa        0      0.0\n",
       "1      0.0\n",
       "2      0.0\n",
       "3      0.0\n",
       "4 ...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "tmp = twitter_df[:10]\n",
    "\n",
    "n_splits = 8\n",
    "n_rows = len(tmp)\n",
    "chunks = [[int(i * n_rows/n_splits), int((i+1) * n_rows/n_splits)]  for i in range(n_splits)]\n",
    "\n",
    "# function to perform vader analysis on portion of the table\n",
    "def vader_worker(row_range):    \n",
    "    return sentiment_analyser(tmp.iloc[row_range[0]:row_range[1]])\n",
    "\n",
    "p = multiprocessing.Pool(processes=n_splits) \n",
    "tmp = p.map(vader_worker, chunks)\n",
    "p.close() \n",
    "del p\n",
    "\n",
    "tmp = pd.concat(tmp)\n",
    "#twitter_df.to_csv(INTERM_DIR+'/XXX/XX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_df['price'].plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax scale it\n",
    "bitcoin_df['returns'] = (bitcoin_df['returns']-bitcoin_df['returns'].min()) / (bitcoin_df['returns'].max()-bitcoin_df['returns'].min())\n",
    "bitcoin_df['returns'].plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bull_lexicon = ['buy','call','forward','long','up','grow','rise','green','hold','carry','bull']\n",
    "bear_lexicon = ['short','sell','down','drop','decrease','red','bear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df['bull_count'] = twitter_df['text'].apply(lambda x: any(substring in x for substring in bull_lexicon))\n",
    "twitter_df['bear_count'] = twitter_df['text'].apply(lambda x: any(substring in x for substring in bear_lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_per_day = twitter_df.reset_index().groupby('date')['index'].count()\n",
    "counts_per_day.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df['score'] = twitter_df['like_count'].astype(int)\n",
    "twitter_df['score'] = twitter_df[['score']].apply(lambda x: x.fillna(x.mean()))\n",
    "twitter_df['abs_score'] = np.abs(twitter_df['score'])\n",
    "\n",
    "#Clustering\n",
    "twitter_df = pd.merge(twitter_df.drop('abs_score', axis=1), \n",
    "                                 twitter_df.groupby('date')['abs_score'].sum(), left_on='date', right_index=True)\n",
    "\n",
    "exp_scalar = 1.1\n",
    "# Normalize score by total (absolute) score for that day\n",
    "twitter_df['score_w'] = twitter_df['score']**exp_scalar /twitter_df['abs_score']\n",
    "twitter_df = twitter_df.drop(['abs_score'], axis=1)\n",
    "twitter_df['compound_sa'] = twitter_df['compound_sa'] * twitter_df['score_w']\n",
    "twitter_df['neg_sa'] = twitter_df['neg_sa'] * twitter_df['score_w']\n",
    "twitter_df['pos_sa'] = twitter_df['pos_sa'] * twitter_df['score_w']\n",
    "twitter_df['neu_sa'] = twitter_df['neu_sa'] * twitter_df['score_w']\n",
    "twitter_df['bull_count'] = twitter_df['bull_count'] * twitter_df['score_w']\n",
    "twitter_df['bear_count'] = twitter_df['bear_count'] * twitter_df['score_w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = twitter_df.groupby('date')[['score','compound_sa','neg_sa','pos_sa','neu_sa','bear_count','bull_count']].agg(\n",
    "    {'compound_sa' : ['sum'], \n",
    "     'neg_sa' : ['sum'], \n",
    "     'neu_sa' : ['sum'], \n",
    "     'pos_sa' : ['sum'],\n",
    "     'bear_count' : ['sum'],\n",
    "     'bull_count' : ['sum'],\n",
    "     'score' : ['mean']}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.plot(x = 'date', y = 'compound_sa', figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.plot(x = 'date', y = 'neg_sa', figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.plot(x = 'date', y = 'pos_sa', figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.plot(x = 'date', y = 'neu_sa', figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.plot(x = 'date', y = 'bear_count', figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.plot(x = 'date', y = 'bull_count', figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.plot(x = 'date', y = 'score', figsize=(20,10))\n",
    "plt.show()\n",
    "twitter_df = twitter_df.drop('score', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fast Fourier Transform on Sentiment Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "def fourier(df, n_dimensions, col):\n",
    "    for n in n_dimensions:\n",
    "        n = round(n)\n",
    "        tmp_ = fft(df[col].values)\n",
    "        tmp_[n:-n] = 0\n",
    "        df[str(n)+'fourier'+col] = np.abs(ifft(tmp_))\n",
    "    return df\n",
    "\n",
    "# how to choose the values of fourier?\n",
    "l = len(twitter_df)\n",
    "twitter_df = fourier(twitter_df, [100, 200], 'compound_sa_sum')\n",
    "twitter_df = fourier(twitter_df, [100, 200], 'pos_sa_sum')\n",
    "twitter_df = fourier(twitter_df, [100, 200], 'neg_sa_sum')\n",
    "twitter_df = fourier(twitter_df, [100, 200], 'neu_sa_sum')\n",
    "returns = fourier(twitter_df['returns'], [200, 400], 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df[['compound_sa_sum','100fouriercompound_sa_sum','200fouriercompound_sa_sum']].plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df[['pos_sa_sum','100fourierpos_sa_sum','200fourierpos_sa_sum']].plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df[['neg_sa_sum','100fourierneg_sa_sum','200fourierneg_sa_sum']].plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df[['neu_sa_sum','100fourierneu_sa_sum','200fourierneu_sa_sum']].plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns[['SPY_Open','200fourierSPY_Open','400fourierSPY_Open']].plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = twitter_df.drop(['compound_sa_sum','pos_sa_sum','neg_sa_sum','neu_sa_sum'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_df(df, df_tickers):\n",
    "    final_df = pd.merge(df, df_tickers, left_on='date_', right_on='Date')\n",
    "    final_df = final_df.set_index('date_')\n",
    "    return final_df\n",
    "\n",
    "final_df = merged_df(twitter_df, returns)\n",
    "#final_df.to_pickle(INTERM_DIR+f'/clean/Final_df_pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "y = bitcoin_df['prices']\n",
    "# change between today and tomorrow is today's predictor\n",
    "y = y.pct_change()[1:].apply(lambda x: 0 if x < 0 else 1).shift(-1)\n",
    "y = y[y.index.isin(final_df.index)]\n",
    "# the information throughout today is only known tomorrow ???\n",
    "# investment decision is made before the open ??\n",
    "X = final_df.shift(1).dropna().to_numpy()\n",
    "window_size = 6\n",
    "## No need to normalize, normalization happens due to feature engineering and bitcoin returns already normalized\n",
    "# Create windows\n",
    "# flip and flip back to make it a reverse window (t-2, t-3... t-window_size)\n",
    "windowed_X = sliding_window_view(np.flip(X, axis=0), window_shape = window_size, axis=0)\n",
    "windowed_X = np.flip(windowed_X, axis=0)\n",
    "windowed_X = np.flip(windowed_X, axis=2)\n",
    "\n",
    "y = y.iloc[window_size:].to_numpy()\n",
    "print(windowed_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# print(sklearn.__version__) # make sure > 0.24\n",
    "\n",
    "X = windowed_X\n",
    "\n",
    "trainsplit = sklearn.model_selection.TimeSeriesSplit(n_splits=2, gap = window_size, test_size = int(0.3 * X.shape[0]))\n",
    "\n",
    "for train_index, rem_index in trainsplit.split(X):\n",
    "\n",
    "    X_train, X_rem = X[train_index], X[rem_index]\n",
    "    y_train, y_rem = y[train_index], y[rem_index]\n",
    "    \n",
    "\n",
    "valsplit = sklearn.model_selection.TimeSeriesSplit(n_splits=2, gap = window_size, test_size = int(0.33 * X_rem.shape[0]))\n",
    "for val_index, test_index in valsplit.split(X_rem):\n",
    "\n",
    "    X_val, X_test = X_rem[val_index], X_rem[test_index]\n",
    "    y_val, y_test = y_rem[val_index], y_rem[test_index]\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(os.path.join(INTERM_DIR, 'train_data.pkl'), 'wb') as f:\n",
    "    pkl.dump([X_train, y_train, X_val, y_val, X_test, y_test], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(INTERM_DIR, 'train_data.pkl'), 'rb') as f:\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = pkl.load(f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
