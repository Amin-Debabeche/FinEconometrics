{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "import pickle as pkl\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "import seaborn as sn\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "RANDOM_SEED = 7\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "INTERM_DIR = '../../../data/compiled_data/'\n",
    "TRAIN_DATA_PATH = os.path.join(INTERM_DIR, 'train_data.pkl')\n",
    "MODEL_DIR = '../models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import build_tcn, build_lstm\n",
    "\n",
    "class PerformTraining:\n",
    "    \n",
    "    \"\"\"\n",
    "    This class performs the training of the desired model\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    seed : int\n",
    "        the integer of the seed utilised for reproducibility \n",
    "    TRAIN_DATA_PATH : str\n",
    "            a string indicating the directory containing preprocessed data split\n",
    "            into train, val and test sets\n",
    "    INTERM_DATA_DIR : str\n",
    "        a string indicating the directory containing intermediate computed data\n",
    "    MODEL_DIR : str\n",
    "        a string indicating the directory containing created models\n",
    "    model_gs_params : dict\n",
    "        a dictionary of preprocessing parameters\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    reproducible_results()\n",
    "        Sets seed and ensures all deterministic operations are reproducible\n",
    "    retrieve_data()\n",
    "        Retrieves the data given the data directory and folders\n",
    "    prepare_data(preprocessing_params, tuning=True):\n",
    "        Combines the preprocessing methods and splits the data for training \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epochs, TRAIN_DATA_PATH, INTERM_DATA_DIR, MODEL_DIR, model_gs_params, model_type, flush, save_plot):\n",
    "        \n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        TRAIN_DATA_PATH : str\n",
    "            a string indicating the directory containing preprocessed data split\n",
    "            into train, val and test sets\n",
    "        INTERM_DATA_DIR : str\n",
    "            a string indicating the directory containing intermediate computed data\n",
    "        MODEL_DIR : str\n",
    "            a string indicating the directory containing created models\n",
    "        model_gs_params : list of lists\n",
    "            a list of lists containing the parameters for model training\n",
    "        \"\"\"\n",
    "\n",
    "        self.seed = 7\n",
    "\n",
    "        self.TRAIN_DATA_PATH = TRAIN_DATA_PATH\n",
    "        self.INTERM_DATA_DIR = INTERM_DATA_DIR\n",
    "        self.MODEL_DIR = MODEL_DIR\n",
    "        self.model_gs_params = model_gs_params\n",
    "        self.max_epochs = epochs\n",
    "        self.model_type = model_type\n",
    "        self.flush = flush\n",
    "        self.save_plot = save_plot\n",
    "        \n",
    "        with open(TRAIN_DATA_PATH, 'rb') as f:\n",
    "            self.X_train, self.y_train, self.X_val, self.y_val, self.X_test, self.y_test = pkl.load(f)\n",
    "            \n",
    "        # random shuffle dataset\n",
    "        p = np.random.permutation(len(self.X_train))\n",
    "        self.X_train, self.y_train = self.X_train[p], self.y_train[p]\n",
    "            \n",
    "        print(f\"The class distributions in the training set are: {np.unique(self.y_train, return_counts=True)}\")\n",
    "        print(f\"The class distributions in the validation set are: {np.unique(self.y_val, return_counts=True)}\")\n",
    "        print(f\"The class distributions in the test set are: {np.unique(self.y_test, return_counts=True)}\")\n",
    "\n",
    "        self.y_train, self.y_val, self.y_test = keras.utils.to_categorical(self.y_train), keras.utils.to_categorical(self.y_val), keras.utils.to_categorical(self.y_test)\n",
    "        \n",
    "        self.reproducible_results()\n",
    "        \n",
    "        if self.model_type == 'tcn':\n",
    "            self.perform_gs_training(build_tcn, os.path.join(self.MODEL_DIR, 'tcn'))\n",
    "            \n",
    "        if self.model_type == 'lstm':\n",
    "            self.perform_gs_training(build_lstm, os.path.join(self.MODEL_DIR, 'lstm'))\n",
    "\n",
    "    def reproducible_results(self):\n",
    "\n",
    "        \"\"\"Obtain reproducible results with keras, source: https://stackoverflow.com/a/52897216\"\"\"\n",
    "\n",
    "        # 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "        os.environ['PYTHONHASHSEED'] = str(self.seed)\n",
    "\n",
    "        # 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "        random.seed(self.seed)\n",
    "\n",
    "        # 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "        # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "        tf.compat.v1.set_random_seed(self.seed)\n",
    "\n",
    "        # 5. Configure a new global `tensorflow` session\n",
    "        session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "        sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "        K.set_session(sess)\n",
    "\n",
    "    def plot_confusion_matrix(self, confusion_matrix, title, save_plot_dir):\n",
    "        \"\"\"Plots a given confusion matrix and saves it\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        confusion_matrix : ndarray\n",
    "            a numpy array of the confusion matrix\n",
    "        title : str\n",
    "            a string of the title name\n",
    "        save_plot_dir : str\n",
    "            a string of where to save the plot\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (ndarray, ndarray)\n",
    "            a tuple of the numpy arrays of the upsampled feature and label arrays\n",
    "        \"\"\"  \n",
    "        # Plot confusion matrix\n",
    "        labels = np.unique(self.y_train)\n",
    "        df_cm = pd.DataFrame(confusion_matrix, index = [i for i in np.unique(self.y_train)], columns = [i for i in np.unique(self.y_train)])\n",
    "        plt.figure(figsize = (10,7))\n",
    "        sn.heatmap(df_cm, annot=True)\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title(title, ha=\"center\")\n",
    "        plt.xticks(np.arange(0.5, len(labels) + 0.5, 1), labels, rotation='horizontal')\n",
    "        plt.yticks(np.arange(0.5, len(labels) + 0.5, 1), labels, rotation='horizontal')\n",
    "        if save_plot_dir is not None: \n",
    "            plt.savefig(f'{save_plot_dir}.pdf', bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def model_param_setup(self, params):\n",
    "        \"\"\"Retrieve from a given ordered list the correct parameters depending on model type\"\"\"\n",
    "        \n",
    "        if self.model_type == 'tcn':\n",
    "\n",
    "            model_params = {'n_layers' : params[0], \n",
    "                            'cnn_dropout_p' : params[1], \n",
    "                            'dense_dropout_p' : params[2], \n",
    "                            'activation' : params[3], \n",
    "                            'n_dense_layers' : params[4], \n",
    "                            'n_dense_neurons' : params[5], \n",
    "                            'batch_normalization' : params[6], \n",
    "                            'kernel_initializer' : params[7],\n",
    "                            'batch_size' : params[8],\n",
    "                            'optimizer' : params[9]}\n",
    "\n",
    "        if self.model_type == 'lstm':\n",
    "\n",
    "            model_params = {'n_layers' : params[0], \n",
    "                            'batch_size' : params[1],\n",
    "                            'lstm_neurons' : params[2], \n",
    "                            'n_dense_neurons' : params[3], \n",
    "                            'dropout' : params[4], \n",
    "                            'activation' : params[5],\n",
    "                            'kernel_initializer' : params[6],\n",
    "                            'optimizer' : params[7]}\n",
    "\n",
    "        return model_params    \n",
    "    \n",
    "    \n",
    "    def perform_gs_training(self, model_fn, checkpoint_filepath):\n",
    "\n",
    "        \"\"\"Performs cross-validated grid search training for selected model function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_fn : function\n",
    "            a function which creates a keras compiled model\n",
    "        checkpoint_filepath : str\n",
    "            a string indicating where to save the plots and grid search results \n",
    "            of the cross-validated grid search\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            a pandas dataframe containing the results of the grid search, \n",
    "            specifically average performance for given hyperparameters\n",
    "        \"\"\"  \n",
    "\n",
    "        pkl_name = os.path.join(checkpoint_filepath, 'gs_res.pkl')\n",
    "        if os.path.isfile(pkl_name) and self.flush==False:\n",
    "            with open(pkl_name, 'rb') as f:\n",
    "                gs_res = pkl.load(f)\n",
    "        else: \n",
    "            gs_res = []\n",
    "\n",
    "        for idx, params in enumerate(self.model_gs_params): \n",
    "\n",
    "            print(\"=================================================\")\n",
    "            print(\"Presenting Results for: %s/%s Hyperparameter Combination\" % (idx+1, len(self.model_gs_params)))\n",
    "\n",
    "            model_params = self.model_param_setup(params)\n",
    "            print(model_params)\n",
    "\n",
    "            batch_size = model_params['batch_size']\n",
    "\n",
    "            # Create backlog for accuracy in each fold\n",
    "            val_fold_accuracy = []\n",
    "            test_fold_accuracy = []\n",
    "\n",
    "            try:     \n",
    "\n",
    "                # Prepare the training dataset\n",
    "                train_dataset = tf.data.Dataset.from_tensor_slices((self.X_train, self.y_train))\n",
    "                train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "\n",
    "                # Prepare the validation dataset\n",
    "                val_dataset = tf.data.Dataset.from_tensor_slices((self.X_val, self.y_val))\n",
    "                val_dataset = val_dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "                \n",
    "                if self.model_type == 'lstm':\n",
    "                    # In stateful lstm, need to have full batches, i.e. a dataset size divisible by batch_size\n",
    "                    rem_last_n_train = (self.X_train.shape[0] % batch_size)\n",
    "                    if rem_last_n_train > 0:\n",
    "                        self.X_train, self.y_train = self.X_train[:-rem_last_n_train], self.y_train[:-rem_last_n_train]\n",
    "\n",
    "                    rem_last_n_val = (self.X_val.shape[0] % batch_size)\n",
    "                    if rem_last_n_val > 0:\n",
    "                        self.X_val, self.y_val = self.X_val[:-rem_last_n_val], self.y_val[:-rem_last_n_val]\n",
    "                    \n",
    "                    rem_last_n_test = (self.X_test.shape[0] % batch_size)\n",
    "                    if rem_last_n_test > 0:\n",
    "                        self.X_test, self.y_test = self.X_test[:-rem_last_n_test], self.y_test[:-rem_last_n_test]\n",
    "                    \n",
    "                model = model_fn(self.X_train, **model_params)\n",
    "\n",
    "                # Create Tensorboard\n",
    "                logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir, update_freq='epoch', profile_batch=0)\n",
    "                # Model Checkpoint Callback\n",
    "                checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(checkpoint_filepath,'checkpoint'), save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)\n",
    "                # Early Stopping Callback\n",
    "                early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 100)\n",
    "\n",
    "                # Train the model\n",
    "                training_history = model.fit(self.X_train, self.y_train, batch_size=batch_size, validation_data=(self.X_val, self.y_val),\n",
    "                                             steps_per_epoch = self.X_train.shape[0] // batch_size if self.model_type == 'lstm' else None, \n",
    "                                             callbacks = [tensorboard_callback,\n",
    "                                                          early_stopping_callback,\n",
    "                                                          checkpoint_callback],\n",
    "                                             epochs=self.max_epochs, verbose=1)\n",
    "                \n",
    "\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "            try: \n",
    "\n",
    "                # Compute confusion matrix across validation folds, and the test set\n",
    "                def compute_confusion_matrix(set_to_predict, true_values, model):\n",
    "                    y_predicted = model.predict(set_to_predict)\n",
    "                    class_pred = np.argmax(y_predicted,axis = 1)\n",
    "                    class_true = np.argmax(true_values,axis = 1)\n",
    "                    res = metrics.confusion_matrix(class_true, class_pred)\n",
    "                    perc_acc = res / res.sum(axis=0)\n",
    "                    return perc_acc\n",
    "\n",
    "                test_accuracy = compute_confusion_matrix(self.X_test, self.y_test, model)\n",
    "                val_accuracy = compute_confusion_matrix(self.X_val, self.y_val, model)\n",
    "                \n",
    "                def plot_roc(set_to_predict, true_values, model, title_prefix, save_plot_dir):\n",
    "                    y_pred_keras = model.predict(set_to_predict)\n",
    "                    class_true = np.argmax(true_values, axis = 1)\n",
    "                    fpr_keras, tpr_keras, thresholds_keras = metrics.roc_curve(class_true, y_pred_keras[:,1])\n",
    "                    auc_keras = metrics.auc(fpr_keras, tpr_keras)\n",
    "                    \n",
    "                    plt.figure()\n",
    "                    lw = 2\n",
    "                    plt.plot(fpr_keras, tpr_keras,\n",
    "                        color=\"darkorange\", lw=lw,\n",
    "                        label=\"ROC curve (area = %0.2f)\" % auc_keras,\n",
    "                    )\n",
    "                    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "                    plt.xlim([0.0, 1.0])\n",
    "                    plt.ylim([0.0, 1.05])\n",
    "                    plt.xlabel(\"False Positive Rate\")\n",
    "                    plt.ylabel(\"True Positive Rate\")\n",
    "                    plt.title(\"%s ROC\" % title_prefix)\n",
    "                    plt.legend(loc=\"lower right\")\n",
    "                    if save_plot_dir is not None: \n",
    "                        plt.savefig(f'{save_plot_dir}.pdf', bbox_inches='tight')\n",
    "                    plt.show()\n",
    "                    \n",
    "                    return auc_keras\n",
    "                \n",
    "\n",
    "                if self.save_plot == True: \n",
    "                    string_model_params = model_params\n",
    "                    del string_model_params['optimizer']\n",
    "                    string_model_params['learning_rate'] = K.eval(model.optimizer.lr)\n",
    "\n",
    "                    string_model_params = [str(x) for x in [*string_model_params.values()]]\n",
    "                    save_plot_dir = os.path.join(checkpoint_filepath, 'plots')\n",
    "                    save_plot_val_dir = os.path.join(save_plot_dir, 'Val CM ' + ' '.join(string_model_params))\n",
    "                    save_plot_test_dir = os.path.join(save_plot_dir, 'Test CM ' + ' '.join(string_model_params))\n",
    "                else: \n",
    "                    save_plot_val_dir = None\n",
    "                    save_plot_test_dir = None\n",
    "\n",
    "                self.plot_confusion_matrix(test_accuracy, 'Test Dataset Accuracy', save_plot_test_dir)    \n",
    "                self.plot_confusion_matrix(val_accuracy, 'Validation Dataset Accuracy', save_plot_val_dir)\n",
    "                \n",
    "                test_roc = plot_roc(self.X_test, self.y_test, model, 'Test', save_plot_test_dir + 'ROC')\n",
    "                val_roc = plot_roc(self.X_val, self.y_val, model, 'Validation', save_plot_val_dir + 'ROC')\n",
    "\n",
    "                curr_gs_res = [model_params, self.model_type, test_accuracy.diagonal(), val_accuracy.diagonal(), test_roc, val_roc]\n",
    "                gs_res.append(curr_gs_res)\n",
    "                with open(pkl_name, 'wb') as f:\n",
    "                    pkl.dump(gs_res, f)\n",
    "\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "        return gs_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Hyperparameter combinations determined\n",
      "The class distributions in the training set are: (array([0, 1]), array([1739, 1754]))\n",
      "The class distributions in the validation set are: (array([0, 1]), array([487, 512]))\n",
      "The class distributions in the test set are: (array([0, 1]), array([291, 203]))\n",
      "=================================================\n",
      "Presenting Results for: 1/40 Hyperparameter Combination\n",
      "{'n_layers': 1, 'cnn_dropout_p': 0.5, 'dense_dropout_p': None, 'activation': 'tanh', 'n_dense_layers': 1, 'n_dense_neurons': 100, 'batch_normalization': False, 'kernel_initializer': 'glorot_uniform', 'batch_size': 128, 'optimizer': <keras.optimizers.optimizer_v2.gradient_descent.SGD object at 0x15e4c8700>}\n",
      "Epoch 1/5000\n",
      "28/28 [==============================] - 6s 79ms/step - loss: 0.7321 - accuracy: 0.4927 - precision: 0.4927 - recall: 0.4927 - val_loss: 0.7164 - val_accuracy: 0.4765 - val_precision: 0.4765 - val_recall: 0.4765\n",
      "Epoch 2/5000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7303 - accuracy: 0.4938 - precision: 0.4938 - recall: 0.4938 - val_loss: 0.7159 - val_accuracy: 0.4765 - val_precision: 0.4765 - val_recall: 0.4765\n",
      "Epoch 3/5000\n",
      "28/28 [==============================] - 1s 23ms/step - loss: 0.7297 - accuracy: 0.4950 - precision: 0.4950 - recall: 0.4950 - val_loss: 0.7155 - val_accuracy: 0.4735 - val_precision: 0.4735 - val_recall: 0.4735\n",
      "Epoch 4/5000\n",
      "28/28 [==============================] - 1s 23ms/step - loss: 0.7296 - accuracy: 0.4924 - precision: 0.4924 - recall: 0.4924 - val_loss: 0.7152 - val_accuracy: 0.4725 - val_precision: 0.4725 - val_recall: 0.4725\n",
      "Epoch 5/5000\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.7241 - accuracy: 0.5073 - precision: 0.5073 - recall: 0.5073 - val_loss: 0.7150 - val_accuracy: 0.4725 - val_precision: 0.4725 - val_recall: 0.4725\n",
      "Epoch 6/5000\n",
      "28/28 [==============================] - 1s 23ms/step - loss: 0.7211 - accuracy: 0.5170 - precision: 0.5170 - recall: 0.5170 - val_loss: 0.7146 - val_accuracy: 0.4725 - val_precision: 0.4725 - val_recall: 0.4725\n",
      "Epoch 7/5000\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.7248 - accuracy: 0.4947 - precision: 0.4947 - recall: 0.4947 - val_loss: 0.7144 - val_accuracy: 0.4745 - val_precision: 0.4745 - val_recall: 0.4745\n",
      "Epoch 8/5000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7261 - accuracy: 0.5036 - precision: 0.5036 - recall: 0.5036 - val_loss: 0.7141 - val_accuracy: 0.4745 - val_precision: 0.4745 - val_recall: 0.4745\n",
      "Epoch 9/5000\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 0.7259 - accuracy: 0.4979 - precision: 0.4979 - recall: 0.4979 - val_loss: 0.7138 - val_accuracy: 0.4735 - val_precision: 0.4735 - val_recall: 0.4735\n",
      "Epoch 10/5000\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7265 - accuracy: 0.4970 - precision: 0.4970 - recall: 0.4970 - val_loss: 0.7135 - val_accuracy: 0.4725 - val_precision: 0.4725 - val_recall: 0.4725\n",
      "Epoch 11/5000\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.7215 - accuracy: 0.4967 - precision: 0.4967 - recall: 0.4967 - val_loss: 0.7132 - val_accuracy: 0.4755 - val_precision: 0.4755 - val_recall: 0.4755\n",
      "Epoch 12/5000\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 0.7214 - accuracy: 0.5107 - precision: 0.5107 - recall: 0.5107 - val_loss: 0.7129 - val_accuracy: 0.4765 - val_precision: 0.4765 - val_recall: 0.4765\n",
      "Epoch 13/5000\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7239 - accuracy: 0.4910 - precision: 0.4910 - recall: 0.4910 - val_loss: 0.7126 - val_accuracy: 0.4775 - val_precision: 0.4775 - val_recall: 0.4775\n",
      "Epoch 14/5000\n",
      "19/28 [===================>..........] - ETA: 0s - loss: 0.7242 - accuracy: 0.4979 - precision: 0.4979 - recall: 0.4979"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d29c69bec458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s Hyperparameter combinations determined\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_randomgs_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m training = PerformTraining(max_epochs, TRAIN_DATA_PATH, INTERM_DIR, MODEL_DIR,\n\u001b[0m\u001b[1;32m     21\u001b[0m                            model_randomgs_params, 'tcn', flush=True, save_plot=True)\n",
      "\u001b[0;32m<ipython-input-2-ba20878591e1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, epochs, TRAIN_DATA_PATH, INTERM_DATA_DIR, MODEL_DIR, model_gs_params, model_type, flush, save_plot)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tcn'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_gs_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_tcn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tcn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ba20878591e1>\u001b[0m in \u001b[0;36mperform_gs_training\u001b[0;34m(self, model_fn, checkpoint_filepath)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 training_history = model.fit(self.X_train, self.y_train, batch_size=batch_size, validation_data=(self.X_val, self.y_val),\n\u001b[0m\u001b[1;32m    240\u001b[0m                                              \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lstm'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                                              callbacks = [tensorboard_callback,\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_epochs = 5000\n",
    "n_random_search = 40\n",
    "\n",
    "batch_size = [128]\n",
    "n_layers = [1] \n",
    "cnn_dropout_p = [None, 0.2, 0.5]\n",
    "dense_dropout_p = [None, 0.2, 0.5]\n",
    "activation = ['relu','tanh']\n",
    "n_dense_layers = [1]\n",
    "n_dense_neurons = [100]\n",
    "batch_normalization = [False, True]\n",
    "kernel_initializer = ['he_normal','glorot_uniform']\n",
    "optimizer = [Adam(learning_rate=0.001), SGD(learning_rate=0.001)] #, clipvalue=0.5\n",
    "\n",
    "model_gs_params = list(itertools.product(*[n_layers, cnn_dropout_p, dense_dropout_p, activation, n_dense_layers, \n",
    "                                           n_dense_neurons, batch_normalization, kernel_initializer, batch_size, optimizer]))\n",
    "model_randomgs_params = random.sample(model_gs_params, n_random_search) if len(model_gs_params) > n_random_search else model_gs_params\n",
    "print(\"%s Hyperparameter combinations determined\" % len(model_randomgs_params))\n",
    "\n",
    "training = PerformTraining(max_epochs, TRAIN_DATA_PATH, INTERM_DIR, MODEL_DIR,\n",
    "                           model_randomgs_params, 'tcn', flush=True, save_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ade/Desktop/Github/FinEconometrics/scripts/sentiment_analysis/models/tcn/gs_res.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-61b5f74d3d15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpkl_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tcn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gs_res.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtcn_gs_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mte_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtcn_gs_res\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#sum(x[-3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ade/Desktop/Github/FinEconometrics/scripts/sentiment_analysis/models/tcn/gs_res.pkl'"
     ]
    }
   ],
   "source": [
    "pkl_name = os.path.join(MODEL_DIR, 'tcn', 'gs_res.pkl')\n",
    "with open(pkl_name, 'rb') as f:\n",
    "    tcn_gs_res = pkl.load(f)\n",
    "    \n",
    "te_auc = [x[-1] for x in tcn_gs_res] #sum(x[-3])\n",
    "max_auc = max(te_auc)\n",
    "max_index = te_auc.index(max_auc)\n",
    "\n",
    "tcn_gs_res[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_name = os.path.join(MODEL_DIR, 'tcn', 'gs_res.pkl')\n",
    "with open(pkl_name, 'rb') as f:\n",
    "    tcn_gs_res = pkl.load(f)\n",
    "    \n",
    "te_auc = [x[-1] for x in tcn_gs_res] #sum(x[-3])\n",
    "max_auc = max(te_auc)\n",
    "max_index = te_auc.index(max_auc)\n",
    "\n",
    "tcn_gs_res[max_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Hyperparameter combinations determined\n",
      "The class distributions in the training set are: (array([0, 1]), array([1739, 1754]))\n",
      "The class distributions in the validation set are: (array([0, 1]), array([487, 512]))\n",
      "The class distributions in the test set are: (array([0, 1]), array([291, 203]))\n",
      "=================================================\n",
      "Presenting Results for: 1/20 Hyperparameter Combination\n",
      "{'n_layers': 2, 'batch_size': 32, 'lstm_neurons': 500, 'n_dense_neurons': 1000, 'dropout': None, 'activation': 'tanh', 'kernel_initializer': 'he_normal', 'optimizer': <keras.optimizers.optimizer_v2.gradient_descent.SGD object at 0x153a15e50>}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (32, 9, 500)              1014000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (32, 500)                 2002000   \n",
      "                                                                 \n",
      " dense (Dense)               (32, 1000)                501000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (32, 2)                   2002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,519,002\n",
      "Trainable params: 3,519,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "109/109 [==============================] - 22s 148ms/step - loss: 0.6978 - accuracy: 0.4948 - precision_440: 0.4948 - recall_440: 0.4948 - val_loss: 0.6973 - val_accuracy: 0.4909 - val_precision_440: 0.4909 - val_recall_440: 0.4909\n",
      "Epoch 2/2000\n",
      "109/109 [==============================] - 19s 173ms/step - loss: 0.6970 - accuracy: 0.4971 - precision_440: 0.4971 - recall_440: 0.4971 - val_loss: 0.6967 - val_accuracy: 0.4929 - val_precision_440: 0.4929 - val_recall_440: 0.4929\n",
      "Epoch 3/2000\n",
      "109/109 [==============================] - 15s 135ms/step - loss: 0.6964 - accuracy: 0.5132 - precision_440: 0.5132 - recall_440: 0.5132 - val_loss: 0.6965 - val_accuracy: 0.4950 - val_precision_440: 0.4950 - val_recall_440: 0.4950\n",
      "Epoch 4/2000\n",
      "109/109 [==============================] - 18s 169ms/step - loss: 0.6962 - accuracy: 0.5120 - precision_440: 0.5120 - recall_440: 0.5120 - val_loss: 0.6965 - val_accuracy: 0.4869 - val_precision_440: 0.4869 - val_recall_440: 0.4869\n",
      "Epoch 5/2000\n",
      "109/109 [==============================] - 14s 130ms/step - loss: 0.6958 - accuracy: 0.5138 - precision_440: 0.5138 - recall_440: 0.5138 - val_loss: 0.6962 - val_accuracy: 0.4990 - val_precision_440: 0.4990 - val_recall_440: 0.4990\n",
      "Epoch 6/2000\n",
      "109/109 [==============================] - 14s 131ms/step - loss: 0.6956 - accuracy: 0.5089 - precision_440: 0.5089 - recall_440: 0.5089 - val_loss: 0.6961 - val_accuracy: 0.5071 - val_precision_440: 0.5071 - val_recall_440: 0.5071\n",
      "Epoch 7/2000\n",
      "109/109 [==============================] - 17s 154ms/step - loss: 0.6953 - accuracy: 0.5106 - precision_440: 0.5106 - recall_440: 0.5106 - val_loss: 0.6960 - val_accuracy: 0.5040 - val_precision_440: 0.5040 - val_recall_440: 0.5040\n",
      "Epoch 8/2000\n",
      "109/109 [==============================] - 15s 138ms/step - loss: 0.6946 - accuracy: 0.5181 - precision_440: 0.5181 - recall_440: 0.5181 - val_loss: 0.6960 - val_accuracy: 0.4960 - val_precision_440: 0.4960 - val_recall_440: 0.4960\n",
      "Epoch 9/2000\n",
      "109/109 [==============================] - 17s 156ms/step - loss: 0.6948 - accuracy: 0.5112 - precision_440: 0.5112 - recall_440: 0.5112 - val_loss: 0.6957 - val_accuracy: 0.5141 - val_precision_440: 0.5141 - val_recall_440: 0.5141\n",
      "Epoch 10/2000\n",
      "109/109 [==============================] - 16s 150ms/step - loss: 0.6947 - accuracy: 0.5169 - precision_440: 0.5169 - recall_440: 0.5169 - val_loss: 0.6958 - val_accuracy: 0.5000 - val_precision_440: 0.5000 - val_recall_440: 0.5000\n",
      "Epoch 11/2000\n",
      " 13/109 [==>...........................] - ETA: 14s - loss: 0.6948 - accuracy: 0.5096 - precision_440: 0.5096 - recall_440: 0.5096"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-3f397e9a43a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s Hyperparameter combinations determined\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_randomgs_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m training = PerformTraining(max_epochs, TRAIN_DATA_PATH, INTERM_DIR, MODEL_DIR,\n\u001b[0m\u001b[1;32m     18\u001b[0m                            model_randomgs_params, 'lstm', flush=True, save_plot=True)\n",
      "\u001b[0;32m<ipython-input-45-ba20878591e1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, epochs, TRAIN_DATA_PATH, INTERM_DATA_DIR, MODEL_DIR, model_gs_params, model_type, flush, save_plot)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_gs_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreproducible_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-ba20878591e1>\u001b[0m in \u001b[0;36mperform_gs_training\u001b[0;34m(self, model_fn, checkpoint_filepath)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 training_history = model.fit(self.X_train, self.y_train, batch_size=batch_size, validation_data=(self.X_val, self.y_val),\n\u001b[0m\u001b[1;32m    240\u001b[0m                                              \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lstm'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                                              callbacks = [tensorboard_callback,\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m-> 2452\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2675\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2676\u001b[0;31m       cache_key, cache_key_deletion_observer = function_context.make_cache_key(\n\u001b[0m\u001b[1;32m   2677\u001b[0m           (args, kwargs))\n\u001b[1;32m   2678\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function_context.py\u001b[0m in \u001b[0;36mmake_cache_key\u001b[0;34m(args, include_tensor_ranks_only)\u001b[0m\n\u001b[1;32m    128\u001b[0m   signature_context = trace_type.SignatureContext(\n\u001b[1;32m    129\u001b[0m       include_tensor_ranks_only)\n\u001b[0;32m--> 130\u001b[0;31m   function_signature = trace_type.make_function_signature(\n\u001b[0m\u001b[1;32m    131\u001b[0m       args, signature_context)\n\u001b[1;32m    132\u001b[0m   return function_cache.FunctionCacheKey(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/core/function/trace_type/signature_builder.py\u001b[0m in \u001b[0;36mmake_function_signature\u001b[0;34m(function_args, signature_context)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mTraceType\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0mall\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m   \"\"\"\n\u001b[0;32m--> 154\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_trace_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/core/function/trace_type/signature_builder.py\u001b[0m in \u001b[0;36mcreate_trace_type\u001b[0;34m(obj, context)\u001b[0m\n\u001b[1;32m     97\u001b[0m   \"\"\"\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSupportsTracingProtocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_tracing_type__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/typing.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                     (not callable(getattr(cls, attr, None)) or\n\u001b[1;32m   1151\u001b[0m                      getattr(instance, attr) is not None)\n\u001b[0;32m-> 1152\u001b[0;31m                     for attr in _get_protocol_attrs(cls)):\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/typing.py\u001b[0m in \u001b[0;36m_get_protocol_attrs\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__annotations__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_abc_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mEXCLUDED_ATTRIBUTES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m                 \u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_epochs = 2000\n",
    "n_random_search = 20\n",
    "\n",
    "n_layers = [2]\n",
    "batch_size = [32]\n",
    "lstm_neurons = [100, 500, 1000]\n",
    "n_dense_neurons = [100, 500, 1000]\n",
    "dropout = [None, 0.2, 0.5, 0.8]\n",
    "activation = ['relu','tanh']\n",
    "kernel_initializer = ['he_normal','glorot_uniform']\n",
    "optimizer = [Adam(learning_rate=0.001), SGD(learning_rate=0.001)]\n",
    "\n",
    "model_gs_params = list(itertools.product(*[n_layers, batch_size, lstm_neurons, n_dense_neurons, dropout, activation, kernel_initializer, optimizer]))\n",
    "model_randomgs_params = random.sample(model_gs_params, n_random_search) if len(model_gs_params) > n_random_search else model_gs_params\n",
    "print(\"%s Hyperparameter combinations determined\" % len(model_randomgs_params))\n",
    "\n",
    "training = PerformTraining(max_epochs, TRAIN_DATA_PATH, INTERM_DIR, MODEL_DIR,\n",
    "                           model_randomgs_params, 'lstm', flush=True, save_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_name = os.path.join(MODEL_DIR, 'lstm', 'gs_res.pkl')\n",
    "with open(pkl_name, 'rb') as f:\n",
    "    tcn_gs_res = pkl.load(f)\n",
    "    \n",
    "te_auc = [x[-1] for x in tcn_gs_res] #sum(x[-3])\n",
    "max_auc = max(te_auc)\n",
    "max_index = te_auc.index(max_auc)\n",
    "\n",
    "tcn_gs_res[max_index]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
